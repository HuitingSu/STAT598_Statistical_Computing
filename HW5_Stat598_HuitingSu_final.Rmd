---
title: "Ridge regression"
author: "Huiting Su"
date: "March 21, 2018"
output: html_document
---
This is a practice of Ridge regression.  
```{r, warning=FALSE, message=FALSE}

```

####(a) Solve.
```{r}
set.seed(2363)
X <- matrix(rnorm(12), 3, 4)
y <- matrix(rnorm(4), 4, 1)
w <- solve(X %*% t(X), X %*% y)
```

####(b) Then the matrices are non-conformable. 

####(c) 
```{r}
lambda <- 5
w2 <- solve(X %*% t(X) + lambda, X %*% y)
w2
```
No solution for (b).

####(d) 
```{r}
train.ridge <- function(ip_data, lambda){
    X <- ip_data[[1]]
    y <- ip_data[[2]]
    w <- solve(X %*% t(X) + lambda, X %*% y)
    return(w)
}
```

####(e) 
```{r}
ip_data <- list(X=X, y=y)
train.ridge(ip_data, lambda = 5)
```

####(f) Generic function.
```{r}
class(ip_data) <- 'ridge'
train <- function(x, lambda) UseMethod('train')
train(ip_data, lambda = 5)
```

####(g) Estimate error.
```{r}
pred_err.ridge <- function(obj, w){
    X <- obj[[1]]
    y <- obj[[2]]
    sum((y - t(X) %*% w)^2)
}
# the prediction error is the residual sum of square, which is the square of L2 norm

pred_err <- function(obj, w) UseMethod('pred_err')
```

```{r}
pred_err(ip_data, w)
```

####(h) 
```{r}
crossval <- function(obj, lambdas, k){
    l <- length(lambdas)
    err <- matrix(0, k, l)
    X <- obj[[1]]
    y <- obj[[2]]
    fold <- floor(length(y)/k)
    for(i in seq(1, fold*k, by=fold)){
        testingX <- X[,i:(i+fold-1)]
        testingy <- y[i:(i+fold-1)]
        testing <- list(testingX, testingy)
        class(testing) <- 'ridge'
        
        trainingX <- X[,-(i:(i+fold-1))]
        trainingy <- y[-(i:(i+fold-1))]
        training <- list(trainingX, trainingy)
        class(training) <- 'ridge'
        
        for(j in 1:l){
            wtrain <- train(training, lambdas[j])
            err[(i-1)/fold +1, j] <- pred_err(testing, wtrain)
        }
    }
    return(err)
}
```

####(i) Load dataset.
Use read.csv because this is better than read.table.
```{r}
credit <- read.csv("Credit.csv")
y <- credit$Balance
X <- t(credit[,c(2,3,4,6,7)])
my_credit <- list(X, y)
class(my_credit) <- 'ridge'
```

####(j) 
```{r}
lambdas <- c(0, 0.1, 0.5, 1, 5, 10, 50, 100, 1000)
cverr <- crossval(my_credit, lambdas, k=5)
print(cverr)
```

####(k) Calculate mean prediction error.
```{r, cache=TRUE}
mean_err <- colMeans(cverr)
mean_err
plot(log(lambdas), mean_err)
```

####(l) Choose the best lambda. 
```{r, cache=TRUE}
nbest <- which.min(mean_err)
cat("The best lambda value is", lambdas[nbest])
train(my_credit, lambdas[nbest])
```